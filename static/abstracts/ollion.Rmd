---
title: "Introduction to Bayesian deep learning"
author: "Charles Ollion"
date: ""
output: 
  html_document:
    theme: journal
---

Deep learning is widely used for regression and classification problems, but the simplest architectures do not capture model uncertainty.
Most widespread solutions provide single point estimates in regression problems instead of designing predictive or posterior distributions.
Several approaches have tried to tie Deep Learning with Bayesian models, such as Bayes by Backprop and practical techniques such as Monte Carlo Dropout. 
During this session, we propose a hands-on tutorial with such approaches, using Python (Tensorflow / Pytorch), on medium-sized and large datasets.
We propose a workshop that you may follow using Google Colab (no installation or requirements).
After an in-depth description of the model and the datasets, we will take time to deeply understand the models and focus on the implementation details. 
 
- **Level:** basic / intermediate
- **Prerequisite:** small experience in Python
- **Duration:** 2h
 
### References

- Weight uncertainty in neural networks aka *Bayes by Backprop* https://arxiv.org/abs/1505.05424
- Dropout as Bayesian approximation aka *Monte Carlo dropout* https://arxiv.org/pdf/1506.02142.pdf
- Evaluating predictive distributions https://arxiv.org/pdf/2110.04629.pdf